---
id: "ServiceContextOptions"
title: "Interface: ServiceContextOptions"
sidebar_label: "ServiceContextOptions"
sidebar_position: 0
custom_edit_url: null
---

## Properties

### callbackManager

• `Optional` **callbackManager**: [`CallbackManager`](../classes/CallbackManager.md)

#### Defined in

[ServiceContext.ts:23](https://github.com/run-llama/llamascript/blob/df4b1ad/packages/core/src/ServiceContext.ts#L23)

___

### chunkOverlap

• `Optional` **chunkOverlap**: `number`

#### Defined in

[ServiceContext.ts:26](https://github.com/run-llama/llamascript/blob/df4b1ad/packages/core/src/ServiceContext.ts#L26)

___

### chunkSize

• `Optional` **chunkSize**: `number`

#### Defined in

[ServiceContext.ts:25](https://github.com/run-llama/llamascript/blob/df4b1ad/packages/core/src/ServiceContext.ts#L25)

___

### embedModel

• `Optional` **embedModel**: [`BaseEmbedding`](../classes/BaseEmbedding.md)

#### Defined in

[ServiceContext.ts:21](https://github.com/run-llama/llamascript/blob/df4b1ad/packages/core/src/ServiceContext.ts#L21)

___

### llm

• `Optional` **llm**: [`OpenAI`](../classes/OpenAI.md)

#### Defined in

[ServiceContext.ts:19](https://github.com/run-llama/llamascript/blob/df4b1ad/packages/core/src/ServiceContext.ts#L19)

___

### llmPredictor

• `Optional` **llmPredictor**: [`BaseLLMPredictor`](BaseLLMPredictor.md)

#### Defined in

[ServiceContext.ts:18](https://github.com/run-llama/llamascript/blob/df4b1ad/packages/core/src/ServiceContext.ts#L18)

___

### nodeParser

• `Optional` **nodeParser**: [`NodeParser`](NodeParser.md)

#### Defined in

[ServiceContext.ts:22](https://github.com/run-llama/llamascript/blob/df4b1ad/packages/core/src/ServiceContext.ts#L22)

___

### promptHelper

• `Optional` **promptHelper**: `PromptHelper`

#### Defined in

[ServiceContext.ts:20](https://github.com/run-llama/llamascript/blob/df4b1ad/packages/core/src/ServiceContext.ts#L20)
