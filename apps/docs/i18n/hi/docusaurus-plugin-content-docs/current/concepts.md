---
sidebar_position: 3
---

# उच्च स्तरीय अवधारणाएँ

`इस दस्तावेज़ का अनुवाद स्वचालित रूप से किया गया है और इसमें त्रुटियाँ हो सकती हैं। परिवर्तन सुझाने के लिए पुल रिक्वेस्ट खोलने में संकोच न करें।`

LlamaIndex.TS आपको अपने डेटा पर LLM-सशक्त एप्लिकेशन (उदा। Q&A, चैटबॉट) बनाने में मदद करता है।

इस उच्च स्तरीय अवधारणाएँ गाइड में, आप सीखेंगे:

- अपने खुद के डेटा का उपयोग करके LLM कैसे सवालों का जवाब दे सकता है।
- LlamaIndex.TS में मुख्य अवधारणाएँ और मॉड्यूल्स के बारे में, जिनका उपयोग अपने स्वयं के क्वेरी पाइपलाइन को संयोजित करने के लिए किया जा सकता है।

## अपने डेटा पर सवालों का जवाब देना

LlamaIndex आपके डेटा के साथ LLM का उपयोग करते समय एक दो स्तरीय प्रक्रिया का उपयोग करता है:

1. **इंडेक्सिंग स्टेज**: ज्ञान आधार की तैयारी, और
2. **क्वेरी स्टेज**: सवाल का जवाब देने के लिए LLM की सहायता करने के लिए ज्ञान से संबंधित संदर्भ प्राप्त करना

![](./_static/concepts/rag.jpg)

इस प्रक्रिया को रिट्रीवल ऑगमेंटेड जनरेशन (RAG) भी कहा जाता है।

LlamaIndex.TS दोनों चरणों को सुपर आसान बनाने के लिए आवश्यक टूलकिट प्रदान करता है।

चलिए विस्तार से प्रत्येक चरण को जानते हैं।

### इंडेक्सिंग स्टेज

LlamaIndex.TS आपको डेटा कनेक्टर्स और इंडेक्स के साथ ज्ञान आधार की तैयारी में मदद करता है।

![](./_static/concepts/indexing.jpg)

[**डेटा लोडर्स**](./modules/high_level/data_loader.md):
डेटा कनेक्टर (उदा। `Reader`) विभिन्न डेटा स्रोतों और डेटा प्रारूपों से डेटा को एक सरल `डॉक्यूमेंट` प्रतिनिधित्व (पाठ और सरल मेटाडेटा) में आपके डेटा को अवलोकन करता है।

[**डॉक्यूमेंट्स / नोड्स**](./modules/high_level/documents_and_nodes.md): एक `डॉक्यूमेंट` किसी भी डेटा स्रोत के आसपास एक साधारण कंटेनर है - उदाहरण के लिए, एक पीडीएफ, एपीआई का आउटपुट, या डेटाबेस से प्राप्त की गई डेटा। एक `नोड` LlamaIndex में डेटा की एटॉमिक इकाई है और एक स्रोत `डॉक्यूमेंट` का "टुकड़ा" प्रतिष्ठित करता है। यह एक समृद्ध प्रतिनिधित्व है जिसमें मेटाडेटा और संबंध (अन्य नोड्स के साथ) शामिल हैं जो सटीक और प्रभावशाली रिट्रीवल आपरेशन को संभव बनाने के लिए होते हैं।

[**डेटा इंडेक्स**](./modules/high_level/data_index.md):
अपने डेटा को अवलोकन करने के लिए, जब आप अपने डेटा को अवलोकित कर लेते हैं, LlamaIndex आपको डेटा को एक ऐसे प्रारूप में इंडेक्स करने में मदद करता है जिसे आसानी से प्राप्त किया जा सकता है।

अंदरूनी तरफ, LlamaIndex कच्चे दस्तावेज़ों को इंटरमीडिएट प्रतिनिधित्व में पारस्परिक रूप से विश्लेषण करता है, वेक्टर एम्बेडिंग्स की गणना करता है, और आपके डेटा को मेमोरी में या डिस्क पर संग्रहीत करता है।

"

### क्वेरी स्टेज

क्वेरी स्टेज में, क्वेरी पाइपलाइन एक उपयोगकर्ता क्वेरी के दिए गए सबसे प्रासंगिक संदर्भ को प्राप्त करता है,
और उसे LLM को संश्लेषित करने के लिए क्वेरी के साथ (साथ ही) एक प्रतिक्रिया का संश्लेषण करता है।

इससे LLM को अपने मूल प्रशिक्षण डेटा में नहीं होने वाली नवीनतम ज्ञान मिलता है,
(हल्लुसिनेशन को भी कम करता है)।

क्वेरी स्टेज में मुख्य चुनौती रिट्रीवल, संगठन, और तर्क करने में होती है (संभवतः कई) ज्ञान आधारों पर।

LlamaIndex उन्हें संरचित तरीके से रैंकिंग प्राथमिकताओं को प्रतिबिंबित करने और संख्यात्मक तरीके से कई ज्ञान आधारों पर तर्क करने में मदद करने वाले संरचनात्मक मॉड्यूल्स प्रदान करता है।

![](./_static/concepts/querying.jpg)

#### बिल्डिंग ब्लॉक्स

[**रिट्रीवर्स**](./modules/low_level/retriever.md):
रिट्रीवर यह निर्धारित करता है कि जब एक क्वेरी दी जाती है तो एक ज्ञान आधार (अर्थात सूचकांक) से संबंधित संदर्भ कैसे प्राप्त किया जाए।
विशेष रिट्रीवल तर्क अलग-अलग सूचकांकों के लिए अलग होता है, सबसे लोकप्रिय वाला एक वेक्टर सूचकांक के खिलाफ घन रिट्रीवल होता है।

[**रिस्पॉन्स सिंथेसाइज़र्स**](./modules/low_level/response_synthesizer.md):
रिस्पॉन्स सिंथेसाइज़र एक प्रतिक्रिया उत्पन्न करता है जो एक LLM से उपयोगकर्ता क्वेरी और दिए गए संदर्भ पाठ के सेट का उपयोग करके बनाई जाती है।

"

#### पाइपलाइन

[**क्वेरी इंजन**](./modules/high_level/query_engine.md):
क्वेरी इंजन एक एंड-टू-एंड पाइपलाइन है जो आपको अपने डेटा पर सवाल पूछने की अनुमति देता है।
इसमें एक प्राकृतिक भाषा क्वेरी ली जाती है, और एक प्रतिक्रिया, साथ ही संदर्भ संदर्भ प्राप्त करके LLM को पास की जाती है।

[**चैट इंजन**](./modules/high_level/chat_engine.md):
चैट इंजन एक एंड-टू-एंड पाइपलाइन है जिसका उपयोग डेटा के साथ बातचीत करने के लिए किया जाता है
(एकल प्रश्न और उत्तर के बजाय कई बार आगे-पीछे)।

"
